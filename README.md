# SUPER STORE APP WEB
Esta aplicaci√≥n es una plataforma de compras desarrollada con una arquitectura basada en microservicios. Est√° dise√±ada para gestionar dos tipos de usuarios:  **clientes** y **administradores**, cada uno con permisos y funcionalidades espec√≠ficas.

El objetivo principal de la aplicaci√≥n es permitir que los usuarios realicen compras de forma f√°cil y organizada. Los usuarios convencionales pueden:
- Ver los productos disponibles en la tienda.

- Agregar productos a su carrito de compras.

- Generar un pedido a partir del contenido del carrito.

- Indicar la direcci√≥n a la que desean que se les env√≠en los productos.

Por otro lado, los administradores cuentan con un perfil m√°s completo que les permite:

-  Visualizar todos los usuarios registrados.

- Consultar todas las √≥rdenes generadas por los clientes. 

- Agregar nuevos productos a la tienda.

- Editar o actualizar la informaci√≥n de los productos existentes.

Acceder a un panel de estad√≠sticas para analizar el desempe√±o general de la tienda.
# Instalaci√≥n y Configuraci√≥n del Proyecto

Para recrear este proyecto correctamente, aseg√∫rese de seguir los pasos de instalaci√≥n detallados a continuaci√≥n.



###  Requisitos Previos

###  Instalaci√≥n de VirtualBox  
Descargue e instale la √∫ltima versi√≥n de **VirtualBox** desde el siguiente enlace:  
üëâ [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)

La instalaci√≥n puede realizarse utilizando los valores predeterminados, sin necesidad de configuraci√≥n adicional.

###  Instalaci√≥n de Vagrant  
Descargue e instale la √∫ltima versi√≥n de **Vagrant** desde el siguiente enlace:  
üëâ [https://releases.hashicorp.com/vagrant/](https://releases.hashicorp.com/vagrant/)

###  Instalaci√≥n del Plugin `vbguest`  
Para asegurar que las *Guest Additions* de VirtualBox se mantengan actualizadas, instale el siguiente plugin ejecutando:

```bash
vagrant plugin install vagrant-vbguest
```

Este plugin mejora el rendimiento e integraci√≥n entre la m√°quina anfitriona y las m√°quinas virtuales.



## Configuraci√≥n y Creaci√≥n de las M√°quinas Virtuales

Este entorno de desarrollo utiliza dos m√°quinas virtuales: una para el **cliente** y otra para el **servidor**.

### Pasos de configuraci√≥n:

1. Cree un directorio y as√≠gnele un nombre, por ejemplo `prueba`:

```bash
mkdir prueba
cd prueba
```

2. Inicialice el proyecto Vagrant dentro del directorio:

```bash
vagrant init
```

Este comando generar√° un archivo llamado `Vagrantfile`, que deber√° modificar con el siguiente contenido.



## 3. Contenido del Archivo `Vagrantfile`

Reemplace el contenido generado por el siguiente:

```ruby
# -*- mode: ruby -*-
# vi: set ft=ruby :
Vagrant.configure("2") do |config|
  if Vagrant.has_plugin? "vagrant-vbguest"
    config.vbguest.no_install = true
    config.vbguest.auto_update = false
    config.vbguest.no_remote = true
  end

  config.vm.define :clienteUbuntu do |clienteUbuntu|
    clienteUbuntu.vm.box = "bento/ubuntu-22.04"
    clienteUbuntu.vm.network :private_network, ip: "192.168.100.3"
    clienteUbuntu.vm.hostname = "clienteUbuntu"
    clienteUbuntu.vm.box_download_insecure = true
  end

  config.vm.define :servidorUbuntu do |servidorUbuntu|
    servidorUbuntu.vm.box = "bento/ubuntu-22.04"
    servidorUbuntu.vm.network :private_network, ip: "192.168.100.2"
    servidorUbuntu.vm.hostname = "servidorUbuntu"
    servidorUbuntu.vm.box_download_insecure = true
  end
end
```

Este archivo define dos m√°quinas virtuales:

- `servidorUbuntu`: con IP `192.168.100.2`  
- `clienteUbuntu`: con IP `192.168.100.3`  

Ambas instanciadas a partir del box `bento/ubuntu-22.04`.



## 4. Arranque y Acceso a las M√°quinas

Una vez configurado el `Vagrantfile`, ejecute el siguiente comando para iniciar ambas m√°quinas virtuales:

```bash
vagrant up
```

Para acceder a cualquiera de ellas mediante SSH, utilice:

```bash
vagrant ssh servidorUbuntu
```

o

```bash
vagrant ssh clienteUbuntu
```

para acceder como root utilice el siguiente comado:
```bash
sudo -i
```

## Node.js (Servidor Ubuntu)



###### Requisitos Previos

- Acceso administrativo (sudo) en el servidor
- Conexi√≥n a Internet estable
- Ubuntu 18.04/20.04/22.04 LTS

#### Pasos de Instalaci√≥n

###### Actualizar el sistema e instalar dependencias


    sudo apt-get update
    sudo apt-get upgrade -y
    sudo apt-get install curl gnupg2 gnupg ca-certificates -y


## Instalaci√≥n y Configuraci√≥n de MySQL

Para instalar MySQL en el sistema, sigue los siguientes pasos:

##### **Instalar el servidor MySQL**

Ejecuta el siguiente comando en la terminal:

```bash
sudo apt-get install mysql-server
```
##### Iniciar el servicio de MySQL
Una vez instalado, inicia el servicio con:

```bash
sudo systemctl start mysql.service
```

##### Corregir un bug de la versi√≥n actual
Antes de ejecutar la herramienta de configuraci√≥n segura, es necesario corregir un bug presente en la versi√≥n m√°s reciente. Para ello, accede al entorno de MySQL:

     sudo mysql
Luego, ejecuta el siguiente comando para permitir el cambio de contrase√±a del usuario root:


    ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
Sal del entorno de MySQL con:

    exit

##### Configurar la instalaci√≥n segura
Ejecuta el siguiente comando para iniciar la configuraci√≥n segura de MySQL:

    sudo mysql_secure_installation
**Durante la configuraci√≥n**:
Cambia nuevamente la contrase√±a del usuario root si se solicita.

## Docker :whale:
Este procedimiento debe realizarse en ambas m√°quinas: servidorUbuntu y clienteUbuntu.

üîß  **Eliminar versiones anteriores de Docker
Antes de instalar Docker, elimine cualquier versi√≥n anterior:**

    for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do 
        sudo apt-get remove -y $pkg
    done
üîë  **Agregar la clave GPG oficial de Docker**

    sudo apt-get update
    sudo apt-get install -y ca-certificates curl
    sudo install -m 0755 -d /etc/apt/keyrings
    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
    sudo chmod a+r /etc/apt/keyrings/docker.asc

**Agregue el repositorio a Apt sources:**


    echo \
     "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
     $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
     sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    sudo apt-get update



üöÄ  **Instalar Docker Engine**

    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
‚öôÔ∏è  **Docker Compose**
Docker Compose tambi√©n debe estar disponible en ambas m√°quinas (servidorPiccoling y clientePiccoling).

‚úÖ **Verificar la instalaci√≥n de Docker Compose**
    docker compose version
üìù Configurar Vim para trabajar con archivos YAML
Cree el archivo de configuraci√≥n de Vim si no existe:


**vim ~/.vimrc**
Agregue la siguiente configuraci√≥n para mejorar la edici√≥n de archivos .yaml y .yml:

    " Configuraci√≥n para trabajar con archivos YAML
    au! BufNewFile,BufReadPost *.{yaml,yml} set filetype=yaml foldmethod=indent
    autocmd FileType yaml setlocal ts=2 sts=2 sw=2 expandtab

### Instalaci√≥n y Configuraci√≥n de Apache Spark en Entorno Distribuido (ServidorUbuntu y ClienteUbuntu) üí´
Este documento describe paso a paso c√≥mo instalar y configurar Apache Spark 3.5.1 sobre Hadoop 3 en dos m√°quinas Ubuntu. La configuraci√≥n est√° dise√±ada para ejecutar Spark en modo standalone distribuido, con una m√°quina actuando como Spark Master y otra como Spark Worker.

**Requisitos Previos**

- Dos m√°quinas Ubuntu con conexi√≥n de red entre ellas.

- Acceso root o permisos de sudo.

- Conectividad entre las IPs:

- ServidorUbuntu: 192.168.100.2

- ClienteUbuntu: 192.168.100.3

##### Actualizaci√≥n de Paquetes e Instalaci√≥n de Java
Apache Spark requiere una m√°quina virtual de Java para funcionar. En ambas m√°quinas, ejecuta los siguientes comandos:


    sudo apt update
    sudo apt install -y openjdk-18-jdk
#####  Configuraci√≥n de Variables de Entorno para Java
Para facilitar el acceso a Java desde cualquier lugar del sistema, creamos un archivo de configuraci√≥n persistente:



    cat <<EOF | sudo tee /etc/profile.d/jdk18.sh
    export JAVA_HOME=/usr/lib/jvm/java-1.18.0-openjdk-amd64
    export PATH=\$PATH:\$JAVA_HOME/bin
    EOF
Aplica la configuraci√≥n inmediatamente:



    source /etc/profile.d/jdk18.sh
Puedes verificar que Java est√© correctamente instalado con:




    java  -version
#####  Preparar el Entorno para Spark
En ambas m√°quinas, crea un directorio dedicado para almacenar los archivos de Apache Spark:



    mkdir labSpark
    cd labSpark
 Descargar y Descomprimir Apache Spark
Descargamos la versi√≥n deseada de Spark  en este caso, 3.5.5 con soporte para Hadoop :



    wget https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz
Procede a descomprimir el archivo:



    
    tar -xvzf spark-3.5.1-bin-hadoop3.tgz
######  Configuraci√≥n del Entorno de Spark
Accede al directorio de configuraci√≥n de Spark:




    cd spark-3.5.1-bin-hadoop3/conf/
Copia la plantilla de configuraci√≥n para editarla:



    cp spark-env.sh.template spark-env.sh
Abre el archivo spark-env.sh con tu editor favorito:




    vim spark-env.sh
Agrega las siguientes variables de entorno al final del archivo, seg√∫n el rol de cada m√°quina:

En ClienteUbuntu (M√°ster)



    SPARK_LOCAL_IP=192.168.100.3
    SPARK_MASTER_HOST=192.168.100.3
En ClienteUbuntu (Worker)


    
    SPARK_LOCAL_IP=192.168.100.2
    SPARK_MASTER_HOST=192.168.100.3
Nota: SPARK_MASTER_HOST debe apuntar a la IP del nodo maestro desde ambas m√°quinas.

‚úÖ Pr√≥ximos pasos
Una vez completada la configuraci√≥n en ambas m√°quinas:

Puedes iniciar el servidor maestro ejecutando en ClienteUbuntu:




    ./sbin/start-master.sh
Luego, inicia el worker en cada m√°quina (incluyendo el cliente si deseas que tambi√©n trabaje como worker):



    ./sbin/start-worker.sh spark://192.168.100.3:7077
Accede a la interfaz web de Spark para verificar los nodos conectados:
üìç http://192.168.100.3:8080

# üêç Instalaci√≥n de Python, PIP y Librer√≠as Necesarias
Para interactuar con Apache Spark desde Python, especialmente mediante PySpark, es necesario tener Python 3, PIP y algunas librer√≠as instaladas en el sistema.

Sigue los pasos a continuaci√≥n en ambas m√°quinas (ServidorUbuntu y ClienteUbuntu).

### Instalaci√≥n de Python 3 y PIP
Ejecuta los siguientes comandos para asegurarte de tener Python 3 y el gestor de paquetes pip instalados:



    sudo apt-get update
	
    sudo apt-get install -y python3
	
    sudo apt-get install -y python3-pip
Nota: Aseg√∫rate de usar python3-pip para instalar la versi√≥n compatible con Python 3.

### Instalaci√≥n de Librer√≠as Python
A continuaci√≥n, instalamos las bibliotecas requeridas para trabajar con Spark y bases de datos desde Python:

- PySpark
Instala el paquete que permite ejecutar c√≥digo Spark desde Python:

```bash
    sudo pip3 install pyspark
```
- PyMySQL
Este paquete permite interactuar con bases de datos MySQL desde Python:


```bash
    pip3 install pymysql
```
‚úÖ Verificaci√≥n
Para asegurarte de que las librer√≠as se han instalado correctamente, puedes ejecutar:




```bash
python3 -c "import pyspark; print('PySpark instalado correctamente')"

python3 -c "import pymysql; print('PyMySQL instalado correctamente')"
```

# Inicio de la Aplicaci√≥n Super-Store App

A continuaci√≥n, se presenta una gu√≠a paso a paso para poner en funcionamiento correctamente la aplicaci√≥n **Super-Store App**.


Este repositorio contiene una aplicaci√≥n completa de Super-Store implementada con arquitectura de microservicios y desplegada usando Docker Compose. El sistema consta de m√∫ltiples servicios interconectados incluyendo frontend, microservicios backend y una base de datos MySQL, todos orquestados para alta disponibilidad y escalabilidad.

**Arquitectura Del Sistema**
La aplicaci√≥n sigue un patr√≥n de dise√±o de microservicios con los siguientes componentes:

**Frontend(super-store-front):** Aplicaci√≥n PHP/JS que sirve la interfaz de usuario (puerto 8080)

**Microservicios Backend(super-store-back):**

Servicio de Usuarios (puerto 3009)

Servicio de Productos (puerto 3001)

Servicio de √ìrdenes (puerto 3010)

Servicio de Carrito de Compras (puerto 3308)

**Servicios de Datos:**

**Base de datos MySQL (init.sql)**(puerto 3307)

**Servidor de An√°lisis** (API Flask en puerto 3020)

------------


#### Requisitos Previos
Antes del despliegue, aseg√∫rese de tener:

- Docker Engine (versi√≥n 20.10.0 o superior)

- Docker Compose (versi√≥n 3.8 o superior)

- Git

- Servidor Ubuntu 

##### Instrucciones de Despliegue
Clonar el repositorio:


    git clone https://github.com/20angela26/Super-Store-App-with-Docker.git
    cd Super-Store-App-with-Docker
Iniciar la aplicaci√≥n:


    docker-compose up -d
**Verificar servicios:**


    docker-compose ps



Para verificar el estado de los servicios:


    docker-compose logs [nombre_servicio]
**Escalabilidad**
Ajuste el n√∫mero de r√©plicas en el archivo docker-compose.yml y redespiegue:

    docker-compose up -d --scale [nombre_servicio]=[cantidad_deseada]

###  Despliegue con Docker Swarm
Este proyecto est√° dise√±ado para ejecutarse tambi√©n en un entorno de cl√∫ster utilizando Docker Swarm, lo cual permite escalar los servicios, distribuir la carga entre varios nodos y lograr alta disponibilidad. A continuaci√≥n, se describe el proceso para inicializar el cl√∫ster, agregar nodos y desplegar los servicios definidos en el archivo docker-compose.yml.

**Inicializar el cl√∫ster Swarm**
En el nodo principal (manager), ejecute el siguiente comando para inicializar el cl√∫ster:


    docker swarm init
Este comando devolver√° una l√≠nea con un token que se usar√° para unir los nodos trabajadores al cl√∫ster. Gu√°rdelo o c√≥pielo.

  **Agregar nodos al cl√∫ster**
En cada nodo trabajador, ejecute el comando que le indic√≥ el nodo manager. El comando tiene una estructura como esta:

    docker swarm join --token <TOKEN> <IP_DEL_MANAGER>

Esto conectar√° el nodo al cl√∫ster como trabajador (worker). Tambi√©n puede agregar m√°s managers si lo desea para mayor disponibilidad.

**Verificar los nodos en el cl√∫ster**
En el nodo manager, ejecute:
    
        docker node ls

Este comando muestra todos los nodos que forman parte del cl√∫ster y su estado actual.

##### Desplegar la aplicaci√≥n con Docker Swarm
Una vez todos los nodos est√©n conectados, puede desplegar la aplicaci√≥n ejecutando en el nodo manager:


    docker stack deploy -c docker-compose.yml super-store

Esto iniciar√° todos los servicios definidos en el archivo docker-compose.yml como parte de una pila (stack) llamada superstore.

**Comprobar los servicios desplegados**
Para verificar que los servicios est√©n corriendo correctamente, utilice:

    docker service ls



## An√°lisis personalizado con Apache Spark 
Si est√°s interesado en realizar un an√°lisis personalizado de esta aplicaci√≥n, puedes hacerlo siguiendo estos pasos:

1. Ingresar al laboratorio Spark
Accede a tu entorno donde tienes instalado Spark (en este caso, por ejemplo, spark-3.5.5-bin-hadoop3).

Crea un directorio donde estar√° tu an√°lisis. Puedes llamarlo, por ejemplo, main.py:

    mkdir ~/spark_analysis
    cd ~/spark_analysis
    touch main.py
En ese archivo (main.py) puedes escribir el c√≥digo necesario para procesar tu dataset con PySpark.

### Configurar el cl√∫ster Spark
**Lanzar el master**
Desde la carpeta spark-3.5.5-bin-hadoop3, inicia el nodo master en modo cliente:

    ./sbin/start-master.sh
Esto levantar√° el servicio Spark Master en el puerto 7077. Puedes comprobarlo accediendo en tu navegador a:


    http://localhost:8080

**Lanzar los workers**
Luego, desde las dos m√°quinas que actuar√°n como workers, ejecuta:

    ./sbin/start-worker.sh spark://<IP_DEL_MASTER>:7077
Esto conectar√° ambos workers al cl√∫ster del master.

Aseg√∫rate de reemplazar <IP_DEL_MASTER> por la IP real del nodo master que se mostr√≥ en la interfaz web o en consola al iniciar el master.

**Ejecutar tu an√°lisis**
Una vez el cl√∫ster est√© listo, puedes ejecutar el archivo main.py as√≠:

    ./bin/spark-submit --master spark://<IP_DEL_MASTER>:7077 ~/spark_analysis/main.py
Esto enviar√° tu an√°lisis al cl√∫ster para que lo procese en paralelo.

**Reemplazar el an√°lisis por defecto del servidor**

La aplicaci√≥n incluye un peque√±o servidor Flask en la carpeta server, el cual sirve un archivo JSON que representa un an√°lisis hecho sobre el dataset original.

**Si deseas usar tu propio dataset o cambiar el an√°lisis, puedes seguir estos pasos**:

Escribe tu script main.py con el nuevo an√°lisis.

Aseg√∫rate de que el script guarde el resultado en formato JSON, por ejemplo:

    resultado.write.json("server/datos.json")

Reemplaza el archivo original del servidor (ubicado en server/Respuestas.json) por el tuyo.

Cuando corras nuevamente el contenedor del servicio servidor, este leer√° tu nuevo archivo y lo expondr√° en el puerto 3020.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
